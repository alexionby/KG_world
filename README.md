# KG_world
Trying to create a perfect data for LLM training and interpreting

## ToDo:
0. Write normal class relations instead of hand-crafted bullshit
1. shuffle before train
2. Do something with '\n' and statement length
3. Fix trouble with dot ., make generated sentences separable, add <eos_token> or another sep
4. ToDo: write custom beam search over model outputs, and vary length, then check whether generated names of `entities` have sens
5. BM25 evaluation